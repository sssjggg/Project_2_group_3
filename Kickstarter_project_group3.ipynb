{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "designed-railway",
   "metadata": {},
   "source": [
    "## 0.1 Import libarys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "damaged-republican",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import to_datetime\n",
    "\n",
    "\n",
    "# plot libarys\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Model preperation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV, cross_validate\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, StandardScaler, LabelEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    " \n",
    "\n",
    "# Classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz  \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Model Metrics\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, roc_curve, confusion_matrix, classification_report, plot_confusion_matrix\n",
    "\n",
    "# for merging the dataframes\n",
    "import os, glob\n",
    "import json\n",
    "\n",
    "# further libarys\n",
    "import itertools\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afraid-stretch",
   "metadata": {},
   "source": [
    "## 0.2 Merging the data frames and loading the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aware-balance",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = 'data/'\n",
    "#all_files = glob.glob(os.path.join(path, '*.csv'))\n",
    "\n",
    "#df_from_each_file = (pd.read_csv(f) for f in all_files)\n",
    "#df_merged   = pd.concat(df_from_each_file, ignore_index=True)\n",
    "#df_merged.to_csv( \"data/Kickstarter.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrapped-liver",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/Kickstarter.csv', index_col = [0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominant-november",
   "metadata": {},
   "source": [
    "# 0.3 Introduction\n",
    "\n",
    "Kickstarter is an online crowdfunding platform that was founded in 2009. We have metrics about projects launched on kickstarter.com from the very beginning to March 2019. Here we will take a first look on which features may influence the success of a kickstarter project.\n",
    "The most successful project ever hosted on kickstarter.com was launched in 2015. [Pebble Time](https://en.m.wikipedia.org/wiki/Pebble_Time), a smartwatch, was backed by more than 78,000 and surpassed its funding goal by 4000% achieving a total of about 20,3 billion USD. In the past years, more and more creative projects (like music and films) have been sucessfully funded on kickstarter.\n",
    "Kickstarter has become increasingly popular to fund projects and ideas. Though, what makes a project successful? How well can we predict if a project is going to be successful? We analyzed\n",
    "- how the number of launched projects changed over the course of 10 years.\n",
    "- how high the goal of those projects were and if it correlated with success.\n",
    "- if time related aspects affected the success of a project (e.g. launch day or deadline).\n",
    "- how successful the projects from various countries were.\n",
    "- how successful projects in the various categories were.\n",
    "- how becoming a staff pick may boost the outcome of your project.\n",
    "- and finally which features determine a positive outcome and how can we predict the success of a project.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rolled-prototype",
   "metadata": {},
   "source": [
    "# 1. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compound-commonwealth",
   "metadata": {},
   "source": [
    "The following columns were droped, becouse they hold no usefull and/or interesting data. The decision was based on a simple consideration of the data frame.\n",
    "\n",
    "For further information about the columns please see columns.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-flooring",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = ['urls','source_url','currency_symbol', 'currency_trailing_code', 'creator', 'location', 'slug', 'usd_type','photo', 'name', 'blurb', 'profile']\n",
    "df.drop(columns = out, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apparent-psychiatry",
   "metadata": {},
   "source": [
    "Dropping the following columns, becouse they only hold 300 values or empty spots and the rest NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "injured-clone",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = ['friends','is_backing','is_starred', 'permissions']\n",
    "df.drop(columns = out, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bound-alberta",
   "metadata": {},
   "source": [
    "Calculate the datetimes, given in seconds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threatened-shepherd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.created_at = pd.to_datetime(df.created_at, unit = 's')\n",
    "df.launched_at = pd.to_datetime(df.launched_at, unit = 's')\n",
    "df.state_changed_at = pd.to_datetime(df.state_changed_at, unit = 's')\n",
    "df.deadline = pd.to_datetime(df.deadline, unit = 's')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imported-decrease",
   "metadata": {},
   "source": [
    "Define the categorical columns and transform theire type from object to category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriental-second",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['country', 'currency','current_currency', 'spotlight','staff_pick','state', 'disable_communication', 'is_starrable']\n",
    "df[categorical] = df[categorical].astype(\"category\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "played-tooth",
   "metadata": {},
   "source": [
    "# 2. Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consolidated-cornwall",
   "metadata": {},
   "source": [
    "### 2.1 Extract data in dictionary in category column into separate columns with leading `\"category_\"`.\n",
    "\n",
    "The category column contained a dictionary with various information. We extracted the the parent category, added this information to the dataframe and dropped the category column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bright-spray",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(pd.DataFrame(df[\"category\"].apply(lambda x: json.loads(x)).to_list()).add_prefix(f\"category_\"))\n",
    "\n",
    "# drop unrelevant categories created by json and change objects to categorical type\n",
    "df.drop(columns=[\"category\"], inplace=True)\n",
    "category_out = [\"category_id\", \"category_color\", \"category_position\", \"category_urls\"]\n",
    "df.drop(columns=category_out, inplace=True)\n",
    "category_categorical = [\"category_parent_id\", \"category_name\", \"category_slug\"]\n",
    "df[category_categorical] = df[category_categorical].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alike-quarterly",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat = df.category_slug.str.title().str.split(\"/\", expand=True).rename(columns={0: \"parent_category_name\", 1: \"subcategory_name\"})\n",
    "df = df.join(df_cat)\n",
    "\n",
    "#df.pivot_table(index=[\"parent_category_name\"], columns=[\"state\"], values=[\"backers_count\", \"pledged_average\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-garbage",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['parent_category_name'].astype(\"category\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interim-bracket",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new feature 'success'\n",
    "df['success'] = df.state == 'successful'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frozen-clause",
   "metadata": {},
   "source": [
    "### 2.2 Analyse duplicates\n",
    "Id is a uniquely identifying id for each project on kickstarter. Therefore, we can check for duplicates based on their id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liked-patrick",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.id.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "found-combat",
   "metadata": {},
   "source": [
    "We have observations with duplicated ids. How many are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooked-youth",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.id.value_counts() == 2).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hispanic-carroll",
   "metadata": {},
   "source": [
    "How many real duplicates, i.e. completely identical rows, do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residential-clause",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "harmful-reason",
   "metadata": {},
   "source": [
    "Duplicates do not give additional information, therefore remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twenty-reward",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collectible-opera",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of projects with duplicate ID: {(df.id.value_counts() == 2).sum()}\") \n",
    "print(f\"Number of observations: {df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handled-apartment",
   "metadata": {},
   "source": [
    "We still have 4411 projects with duplicate ID in 186677 observations, for now we assume their amount small enough to continue with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annual-polymer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "announced-hebrew",
   "metadata": {},
   "source": [
    "### 2.3 Adding additional columns calculated with the original given data\n",
    "\n",
    "Projects can be launched for different time spans. We calculated the duration each project was online (based on launch date and deadline. Further, the set up of a project may take some time. We calculated the preparation time of each project based on the date the project was created and when it was eventually launched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quick-congress",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calulate the time between launched_at and deadline\n",
    "df['duration'] =  (df.deadline - df.launched_at).dt.days.astype('int')\n",
    "\n",
    "# Calculate the time between project creation (on kickstarter) and lounching it (days)\n",
    "df['prep_time'] =  (df.launched_at - df.created_at ).dt.days.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manufactured-summer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.prep_time.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complicated-philippines",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.prep_time.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brazilian-swiss",
   "metadata": {},
   "source": [
    "### 2.4 Conversion of usd_goal and creating additional goal and pledged related data columns\n",
    "\n",
    "\n",
    "The projects are not solely US-based. To be able to compare the various project goals we transformed the goal based on the given static USD rate. We also computed the ratio between the pledged amount and the number of backers for each project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extended-retailer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversion of goal in USD with static_usd_rate\n",
    "df[\"usd_goal\"] = df.goal * df.static_usd_rate\n",
    "\n",
    "df[\"log_usd_goal\"] = np.log10(df.usd_goal)\n",
    "\n",
    "# average plegde\n",
    "df[\"pledged_average\"] = df.usd_pledged / df.backers_count\n",
    "df[\"log_pledged_average\"] = np.log10(df.pledged_average)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structured-traffic",
   "metadata": {},
   "source": [
    "The goals of each projects varied a lot. Here we bin the goals in different categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "activated-hybrid",
   "metadata": {},
   "outputs": [],
   "source": [
    "def money(x):\n",
    "        if x <= 100: return '100 USD'\n",
    "        elif x <= 250 : return '250 USD' \n",
    "        elif x <= 500 : return '500 USD'\n",
    "        elif x <= 1000 : return '1,000 USD'\n",
    "        elif x <= 5000 : return '5,000 USD'\n",
    "        elif x <= 10000 : return '10,000 USD'\n",
    "        elif x <= 50000 : return '50,000 USD'\n",
    "        elif x <= 100000 : return '100,000 USD'\n",
    "        elif x <= 500000 : return '500,000 USD'\n",
    "        elif x <= 1000000 : return '1,000,000 USD'\n",
    "        elif x <= 5000000 : return '5,000,000 USD'\n",
    "        elif x <= 10000000 : return '10,000,000 USD'\n",
    "        elif x >= 10000000 : return '> 10,000,000 USD'\n",
    "\n",
    "df[\"goal_bins\"] = pd.Categorical(df.usd_goal.apply(money), \n",
    "                ['100 USD', '250 USD', '500 USD', '1,000 USD', '5,000 USD', '10,000 USD',\n",
    "                 '50,000 USD', '100,000 USD', '500,000 USD', '1,000,000 USD', '5,000,000 USD', '10,000,000 USD', '> 10,000,000 USD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-aluminum",
   "metadata": {},
   "outputs": [],
   "source": [
    "def money2(x):\n",
    "        if x <= 100: return '1,000 USD'\n",
    "        elif x <= 5000 : return '5,000 USD'\n",
    "        elif x <= 10000 : return '10,000 USD'\n",
    "        elif x <= 50000 : return '50,000 USD'\n",
    "        elif x <= 100000 : return '100,000 USD'\n",
    "        elif x <= 500000 : return '500,000 USD'\n",
    "        elif x > 500000 : return '> 500,000 USD'\n",
    "\n",
    "df[\"goal_bins2\"] = pd.Categorical(df.usd_goal.apply(money2), \n",
    "                ['1,000 USD', '5,000 USD', '10,000 USD','50,000 USD', '100,000 USD', '500,000 USD', '> 500,000 USD'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "activated-paraguay",
   "metadata": {},
   "source": [
    "### 2.5 Preparing the time related data for visualization \n",
    "\n",
    "Subdevision launched, deadline, changed and created in hours (_H), days (_D), months (_M) and years (_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulation-nepal",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['launched_Y'] = df.launched_at.dt.year.astype('int')\n",
    "df['launched_M'] = df.launched_at.dt.month.astype('int')\n",
    "df['launched_D'] = df.launched_at.dt.day.astype('int')\n",
    "df['launched_H'] = df.launched_at.dt.hour.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorrect-clone",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['deadline_Y'] = df.deadline.dt.year.astype('int')\n",
    "df['deadline_M'] = df.deadline.dt.month.astype('int')\n",
    "df['deadline_D'] = df.deadline.dt.day.astype('int')\n",
    "df['deadline_H'] = df.deadline.dt.hour.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historical-temple",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['changed_Y'] = df.state_changed_at.dt.year.astype('int')\n",
    "df['changed_M'] = df.state_changed_at.dt.month.astype('int')\n",
    "df['changed_D'] = df.state_changed_at.dt.day.astype('int')\n",
    "df['changed_H'] = df.state_changed_at.dt.hour.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apart-effect",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['created_Y'] = df.created_at.dt.year.astype('int')\n",
    "df['created_M'] = df.created_at.dt.month.astype('int')\n",
    "df['created_D'] = df.created_at.dt.day.astype('int')\n",
    "df['created_H'] = df.created_at.dt.hour.astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "still-hopkins",
   "metadata": {},
   "source": [
    "Project were online between 1 to 93 days. We subdevided the preparation time into the following 'duration_bins: '1 day', '3 days', '1 week', '2 weeks', '1 month', '2 months' and '3 months'. Apart from '1 day', all other bins should be understood as \"as long as\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "congressional-kidney",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dur_kick(x):\n",
    "        if x == 1: return '1 day'\n",
    "        elif x == 2 or x <= 3 : return '3 days' \n",
    "        elif x == 4 or x <= 7 : return '1 week'\n",
    "        elif x == 8 or x <= 14 : return '2 weeks'\n",
    "        elif x == 15 or x <= 30 : return '1 month'\n",
    "        elif x == 31 or x <= 60 : return '2 months'\n",
    "        elif x == 61 or x <= 93 : return '3 months'\n",
    "\n",
    "df[\"duration_bins\"] = pd.Categorical(df.duration.apply(dur_kick), \n",
    "                ['1 day', '3 days', '1 week', '2 weeks', '1 month', '2 months','3 months'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "logical-asset",
   "metadata": {},
   "source": [
    "The preparation of a project was rather different. Thus, we we created another bin 'prep_bins' ('1 day', '3 days', '1 week', '2 weeks', '1 month', '2 months','3 months', '6 months', '1 year' and '> 1 year'). Here, each given bin should be read as \"at least as long as\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normal-course",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep(x):\n",
    "        if x <= 1: return '1 day'\n",
    "        elif x <= 3 : return '3 days' \n",
    "        elif x <= 7 : return '1 week'\n",
    "        elif x <= 14 : return '2 weeks'\n",
    "        elif x <= 30 : return '1 month'\n",
    "        elif x <= 60 : return '2 months'\n",
    "        elif x <= 90 : return '3 months'\n",
    "        elif x <= 180 : return '6 months'\n",
    "        elif x <= 360 : return '1 year'\n",
    "        else : return '> 1 year'\n",
    "\n",
    "df[\"prep_bins\"] = pd.Categorical(df.prep_time.apply(prep), \n",
    "                ['1 day', '3 days', '1 week', '2 weeks', '1 month', '2 months','3 months', '6 months', '1 year', '> 1 year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fourth-bible",
   "metadata": {},
   "source": [
    "As we calculated the date for each project, we might as well assign weekdays for the launch day and the deadline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "horizontal-government",
   "metadata": {},
   "outputs": [],
   "source": [
    "wday = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "\n",
    "def weekday(x): return wday[x]       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fuzzy-screening",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['launch_day'] = df.launched_at.dt.to_period('D').dt.weekday\n",
    "df['launch_day'] = pd.Categorical(df.launch_day.apply(weekday), \n",
    "                ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "according-syracuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['deadline_day'] = df.deadline.dt.to_period('D').dt.weekday\n",
    "df['deadline_day'] = pd.Categorical(df.deadline_day.apply(weekday), \n",
    "                ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optimum-double",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['changed_day'] = df.state_changed_at.dt.to_period('D').dt.weekday\n",
    "df['changed_day'] = pd.Categorical(df.changed_day.apply(weekday), \n",
    "                ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charming-bouquet",
   "metadata": {},
   "source": [
    "# 4. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baking-locking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seting figuresize and lable size globally\n",
    "plt.rcParams['figure.figsize']=(12,8)\n",
    "plt.rcParams['font.size']=14\n",
    "\n",
    "sns.set_theme(palette = 'pastel', \n",
    "              font_scale=1.25)\n",
    "\n",
    "# setting the colors\n",
    "state = df.state.unique().tolist()\n",
    "state_colors=['#fa9fb5', '#7a0177', '#8c96c6', '#f768a1', '#dadaeb']\n",
    "COLOR_STATE = dict(zip(state, state_colors))\n",
    "COLOR_TIME = '#084594'  # dark blue-ish\n",
    "COLOR_COUNTRY = '#6baed6'  # blue-ish\n",
    "COLOR_CATEGORY = '#2171b5' # different blue\n",
    "COLOR_SUCCESS = '#7a0177'  # dark purple\n",
    "COLOR_MONEY = '#4292c6'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rolled-medicine",
   "metadata": {},
   "source": [
    "## 4.1. The influence of time related data on the success"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empty-spare",
   "metadata": {},
   "source": [
    "### 4.1.1 Closer look at the launched related data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "every-fields",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.launched_Y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "global-visitor",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['launched_M'].groupby(df['launched_Y']).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outstanding-canal",
   "metadata": {},
   "source": [
    "Let's look at the overall number of projects per year. Since its start in 2009, Kickstarter has has increasing number of projects on its platform. The highest number was reached in 2015 with almost 38,000 projects - so far. The last years there have been a bit more than 27,000 projects. However, we do expect an uptick in projects as numbers have risen in 2018 again and in 2019 there are already more than 8,000 projects in the first three months of the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prompt-orbit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of the number of projects started annually \n",
    "sns.countplot(x = df.launched_Y.sort_values(), color = COLOR_TIME).set(xlabel='Year', ylabel = 'Number of projects')\n",
    "\n",
    "#plt.savefig(\"images/projects_year.png\",  bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aging-panic",
   "metadata": {},
   "source": [
    "The number of projects also changed with the years as between 2012 and 2017 kickstarter was launched in a lot more countries, particularly in 2015 ([source](https://en.wikipedia.org/wiki/Kickstarter))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enabling-religion",
   "metadata": {},
   "source": [
    "| Country      | Launch    | \n",
    "|--- | --- |\n",
    "| Country | Launch |  \n",
    "| Great Britian | October 2012 | \n",
    "| Canada | September 2013 | \n",
    "| Australia and New Zealand | November 2013 | \n",
    "| Netherland | April 2014 | \n",
    "| Denmark, Ireland, Norway and Sweden | April 2014 |\n",
    "|  Germany | April 2015 | \n",
    "| France, Spain | May 2015 | \n",
    "| Austria, Belgium, Italy, Luxembourg and Switzerland |  June 2015 | \n",
    "| Singapore and Hong Kong |  August 2016 | \n",
    "| Mexico |  September 2016 | \n",
    "| Japan |  November 2017 | "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improved-offering",
   "metadata": {},
   "source": [
    "The success rate of projects was fairly high in the first years of Kickstarter (almost 80%). However, it dropped in 2014 below 50%. After another low in 2015, the success rate as increased slightly over the last years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strong-jersey",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of the project state (read: success rate) over the different years.\n",
    "ax = sns.histplot(x='launched_Y',\n",
    "                 hue= 'state',\n",
    "                 stat = 'probability',\n",
    "                 data=df,\n",
    "                 multiple=\"fill\",\n",
    "                 palette = COLOR_STATE\n",
    "                 )\n",
    "ylabels = ['{:,.0f}'.format(y) for y in ax.get_yticks()*100]\n",
    "ax.set_yticklabels(ylabels)\n",
    "\n",
    "ax.set(xlabel=\"Year\")\n",
    "ax.set(ylabel=\"Percent\")\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0., \n",
    "           labels = ['suspended', 'successful', ' live','failed', 'canceled'], labelspacing=1.2)\n",
    "\n",
    "#plt.savefig(\"images/state_year.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "union-domestic",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(x = df.launched_D.sort_values(), color = COLOR_TIME)\n",
    "\n",
    "ax.set(xlabel='Day of the month (launch)', ylabel = 'Number of projects')\n",
    "\n",
    "ylabels = ['{:,.0f}'.format(y) for y in ax.get_yticks()]\n",
    "ax.set_yticklabels(ylabels)\n",
    "\n",
    "#plt.savefig(\"images/projects_month.png\" , bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coastal-teddy",
   "metadata": {},
   "source": [
    "As you can see above, projects were launched on all days of the months and fairly evenly distributed. The first, the 15th and the 31st do stick out. But it's more interesting to see whether the launching day does indeed impact the success of a project. However, when looking at the state of the projects (below) we can see that it does not seem to be important on which day of the week a project is launched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infinite-malpractice",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.histplot(x='launch_day',\n",
    "                 hue= 'state',\n",
    "                 stat = 'probability',\n",
    "                 data=df,\n",
    "                 multiple=\"fill\",\n",
    "                 palette = COLOR_STATE\n",
    "                 )\n",
    "#ax.set_xticklabels(ax.get_xticklabels(),rotation=40)\n",
    "ax.set(xlabel=\"Weekday\")\n",
    "ax.set(ylabel=\"Percent\")\n",
    "\n",
    "ylabels = ['{:,.0f}'.format(y) for y in ax.get_yticks()*100]\n",
    "ax.set_yticklabels(ylabels)\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0., \n",
    "           labels = ['suspended', 'successful', ' live','failed', 'canceled'], labelspacing=1.2)\n",
    "\n",
    "#plt.savefig(\"images/state_weekday.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outside-tomato",
   "metadata": {},
   "source": [
    "### 4.1.2 Exploration of the influence of the project duration on kickstarter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naughty-physiology",
   "metadata": {},
   "source": [
    "When preparing a project is also interesting to know for how long your project should be online to be successful - and if duration has an effect on your success. The previous projects were mostly online for 1 month, followed by 3 months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grateful-kenya",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of duration projects were online (count)\n",
    "ax = sns.countplot(x = df.duration_bins, color = COLOR_TIME)\n",
    "\n",
    "ax.set(xlabel='Duration between launch and deadline', ylabel = 'Number of projects')\n",
    "ylabels = ['{:,.0f}'.format(y) for y in ax.get_yticks()]\n",
    "ax.set_yticklabels(ylabels)\n",
    "\n",
    "#plt.savefig(\"images/duration_bin_counts.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dietary-colon",
   "metadata": {},
   "source": [
    "So does it have an effect on the success?\n",
    "\n",
    "It depends. Projects that have been online for at least 2 weeks or at least 3 months were more successful than other projects online for shorter (or longer) time spans. Also projects that were online for up to 1 week were more likely to be suspended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "voluntary-modem",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of duration bins in relation to state of projects\n",
    "ax = sns.histplot(x='duration_bins',\n",
    "                 hue= 'state',\n",
    "                 stat = 'probability',\n",
    "                 data=df,\n",
    "                 multiple=\"fill\",\n",
    "                 palette = COLOR_STATE\n",
    "                 )\n",
    "ax.set(xlabel=\"Duration between launch and deadline\")\n",
    "ax.set(ylabel=\"Percent\")\n",
    "\n",
    "ylabels = ['{:,.0f}'.format(y) for y in ax.get_yticks()*100]\n",
    "ax.set_yticklabels(ylabels)\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0., \n",
    "           labels = ['suspended', 'successful', ' live','failed', 'canceled'], labelspacing=1.2)\n",
    "\n",
    "#plt.savefig(\"images/duration_bin_state.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constitutional-strengthening",
   "metadata": {},
   "source": [
    "Looking at the asked goal of a project, we can see that the duration of \"3 months\" may be distorting our plot above. It is likley that these projects were not successful because they were online for a longer period but rather because they were asking for a lower goal (compared to the projects in the two months bin)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fuzzy-ethiopia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization  of the goals in relation to the duration the projects were online \n",
    "ax = sns.scatterplot(x = df.duration_bins, y = df.usd_goal, color = COLOR_TIME)\n",
    "\n",
    "ax.set(xlabel=\"Duration between launch and deadline\")\n",
    "ax.set(ylabel=\"Goal ins US Dollar\")\n",
    "\n",
    "ylabels = ['{:,.0f}'.format(y) for y in ax.get_yticks()]\n",
    "ax.set_yticklabels(ylabels)\n",
    "\n",
    "#plt.savefig(\"images/duration_bin_goal.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ignored-timer",
   "metadata": {},
   "source": [
    "### 4.1.3 Preparation time\n",
    "How long did it take between projects being created and actually launched on Kickstarter, and how did this affect their success? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rolled-error",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(x = df.prep_bins, color = COLOR_TIME)\n",
    "\n",
    "ax.set(xlabel=\"Preparation time (duration between creation and launch)\")\n",
    "ax.set(ylabel=\"Number of projects\")\n",
    "\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=40)\n",
    "\n",
    "ylabels = ['{:,.0f}'.format(y) for y in ax.get_yticks()]\n",
    "ax.set_yticklabels(ylabels)\n",
    "\n",
    "#plt.savefig(\"images/preparation_bin_count.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supported-auckland",
   "metadata": {},
   "source": [
    "A lot of the projects on kickstarter were created and put online within 24 hours. Another higher number of projects were prepared for up to one month. The numbers of project decline with a longer preparation time, but even projects that were worked on for more than a year were brought online eventually.\n",
    "\n",
    "So did this preparation time have an effect on the success (and maybe other possible states) of these projects?\n",
    "\n",
    "As you can see below projects that were prepared for one to three months were more likely to be successful. A longer preparation did not seem to have a positive effect on the outcome. And: projects that were launched very fast were more likely to be suspended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absent-insulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of state of a project in relation to preparation time\n",
    "ax = sns.histplot(x='prep_bins',\n",
    "                 hue= 'state',\n",
    "                 stat = 'probability',\n",
    "                 data=df,\n",
    "                 multiple=\"fill\",\n",
    "                 palette = COLOR_STATE\n",
    "                 )\n",
    "#ax.set_xticklabels(ax.get_xticklabels(),rotation=40)\n",
    "ax.set(xlabel=\"Duration between creation and launch\")\n",
    "ax.set(ylabel=\"Percent\")\n",
    "\n",
    "ylabels = ['{:,.0f}'.format(y) for y in ax.get_yticks()*100]\n",
    "ax.set_yticklabels(ylabels)\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0., \n",
    "           labels = ['suspended', 'successful', ' live','failed', 'canceled'], labelspacing=1.2)\n",
    "\n",
    "#plt.savefig(\"images/prep_bin_state.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removable-occupation",
   "metadata": {},
   "source": [
    "### 4.1.4 Deadline\n",
    "\n",
    "Let's take a closer look at the deadline. The data shows it doesn't seem to have an effect when a project is ending. The success rate seems fairly evenly distributed over the months of an year (in terms of deadline)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "terminal-tract",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of the state of a project in relation to the month of the deadline\n",
    "ax = sns.histplot(x='deadline_M',\n",
    "                 hue= 'state',\n",
    "                 stat = 'probability',\n",
    "                 data=df,\n",
    "                 multiple=\"fill\",\n",
    "                 palette = COLOR_STATE\n",
    "                 )\n",
    "#ax.set_xticklabels(ax.get_xticklabels(),rotation=40)\n",
    "ax.set(xlabel=\"Month (in numbers)\")\n",
    "ax.set(ylabel=\"Percent\")\n",
    "\n",
    "ylabels = ['{:,.0f}'.format(y) for y in ax.get_yticks()*100]\n",
    "ax.set_yticklabels(ylabels)\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0., \n",
    "           labels = ['suspended', 'successful', ' live','failed', 'canceled'], labelspacing=1.2)\n",
    "\n",
    "#plt.savefig(\"images/deadline_M_state.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hindu-samba",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(x = df.deadline_D.sort_values(), color = COLOR_TIME)\n",
    "\n",
    "ax.set(xlabel=\"Day of the month of the deadline\")\n",
    "ax.set(ylabel=\"Number of projects\")\n",
    "\n",
    "ylabels = ['{:,.0f}'.format(y) for y in ax.get_yticks()]\n",
    "ax.set_yticklabels(ylabels)\n",
    "\n",
    "#plt.savefig(\"images/deadline_D_count.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excellent-employment",
   "metadata": {},
   "source": [
    "So maybe it has an effect on which days of the month the most deadlines were. In fact, the plot looks fairly similar to the plot of the launch day. The first, 15th/16th and the 30th of a month are popular deadlines. And just like the launch day the weekday does not seem to have an effect on the outcome of a project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "growing-milan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of the state of a project in relation to the weekday of the deadline\n",
    "ax = sns.histplot(x='deadline_day',\n",
    "                 hue= 'state',\n",
    "                 stat = 'probability',\n",
    "                 data=df,\n",
    "                 multiple=\"fill\",\n",
    "                 palette = COLOR_STATE\n",
    "                 )\n",
    "#ax.set_xticklabels(ax.get_xticklabels(),rotation=40)\n",
    "ax.set(xlabel=\"Duration between creation and launch\")\n",
    "ax.set(ylabel=\"Percent\")\n",
    "\n",
    "ylabels = ['{:,.0f}'.format(y) for y in ax.get_yticks()*100]\n",
    "ax.set_yticklabels(ylabels)\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0., \n",
    "           labels = ['suspended', 'successful', ' live','failed', 'canceled'], labelspacing=1.2)\n",
    "\n",
    "#plt.savefig(\"images/deadline_D_state.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rotary-pocket",
   "metadata": {},
   "source": [
    "## 4.2 Influence of project goals on success"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressing-plaintiff",
   "metadata": {},
   "source": [
    "The goals of the projects do vary a lot. As mentioned before projects with goals as high as several million US Dollars may be very successful. Though how successful are these projects compared to more reasonable goals?\n",
    "\n",
    "The goals have been binned in categories reaching from 100 USD to above 10,000,000 USD. Here is the count. Projects with goals higher than 500,000 USD are rare. More common are projects witht goals in the range of several thousand USD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single-lover",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(df['goal_bins']).goal_bins.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "played-butter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of duration projects were online (count)\n",
    "ax = sns.countplot(y = df.goal_bins, color = COLOR_MONEY)\n",
    "\n",
    "ax.set(ylabel='Goal', xlabel = 'Number of projects')\n",
    "xlabels = ['{:,.0f}'.format(x) for x in ax.get_xticks()]\n",
    "ax.set_xticklabels(xlabels)\n",
    "\n",
    "#plt.savefig(\"images/goal_bin_counts.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indie-variable",
   "metadata": {},
   "source": [
    "To plot the success of the different goals, we chose broader (and fewer) bins starting from 1,000 USD to above 500,000 USD. Here we can see, that the success of projects with high goals are less more likely to be successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifth-ferry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of state of a project in relation to preparation time\n",
    "ax = sns.histplot(x='goal_bins2',\n",
    "                 hue= 'state',\n",
    "                 stat = 'probability',\n",
    "                 data=df,\n",
    "                 multiple=\"fill\",\n",
    "                 palette = COLOR_STATE\n",
    "                 )\n",
    "#ax.set_xticklabels(ax.get_xticklabels(),rotation=40)\n",
    "ax.set(xlabel=\"Goal\")\n",
    "ax.set(ylabel=\"Percent\")\n",
    "\n",
    "ylabels = ['{:,.0f}'.format(y) for y in ax.get_yticks()*100]\n",
    "ax.set_yticklabels(ylabels)\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0., \n",
    "           labels = ['suspended', 'successful', ' live','failed', 'canceled'], labelspacing=1.2)\n",
    "\n",
    "#plt.savefig(\"images/goal_bin2_state.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funded-observation",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_goal = df.groupby(df['goal_bins2']).success.mean().reset_index().rename(columns={\"success\":\"success_goal\"})\n",
    "df = df.merge(s_goal, how = 'outer', left_on = 'goal_bins2', right_on = 'goal_bins2')\n",
    "s_goal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swiss-falls",
   "metadata": {},
   "source": [
    "## 4.3 Influence of the location on success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reliable-healthcare",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(df['country']).country.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "digital-engine",
   "metadata": {},
   "source": [
    "The most projects are generated in the US, by far, which is not surprising as Kickstarter is based in Brooklyn, N.Y.C. Though, also a quite large number come from Great Britian and Canada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regular-cholesterol",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of project counts in relation to country \n",
    "ax = sns.countplot(x = df.country.sort_values(), color = COLOR_COUNTRY)\n",
    "\n",
    "ax.set(xlabel=\"Country\")\n",
    "ax.set(ylabel=\"Number of projects\")\n",
    "\n",
    "ylabels = ['{:,.0f}'.format(y) for y in ax.get_yticks()]\n",
    "ax.set_yticklabels(ylabels)\n",
    "\n",
    "#plt.savefig(\"images/country_count.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norman-pleasure",
   "metadata": {},
   "source": [
    "To check whether the country of were a project is based has an impact we created a column that displays the success rate of a project depending on the location. For this we ignore the other states a project might have - besides failed (canceled, suspended, live)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-paragraph",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_country = df.groupby(df['country']).success.mean().reset_index().rename(columns={\"success\":\"success_country\"})\n",
    "\n",
    "df = df.merge(s_country, how = 'outer', left_on = 'country', right_on = 'country')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "korean-sister",
   "metadata": {},
   "source": [
    "The most successful projects were launched in Hongkong and Luxemburg (above 60% success rate), Great Britian and Japan being the runners up. Remarkedly, project from Italy are rarely successful (below 30%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bound-surrey",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of success rate in relation to location/country\n",
    "ax = sns.barplot(x = df.country, y = df.success_country, color = COLOR_SUCCESS)\n",
    "\n",
    "ax.set(xlabel=\"Country\")\n",
    "ax.set(ylabel=\"Success in percent\")\n",
    "\n",
    "ylabels = ['{:,.0f}'.format(y) for y in ax.get_yticks()*100]\n",
    "ax.set_yticklabels(ylabels)\n",
    "\n",
    "#plt.savefig(\"images/country_success.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unauthorized-tomato",
   "metadata": {},
   "source": [
    "## 4.4 Influence of the categorical data columns "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unsigned-mountain",
   "metadata": {},
   "source": [
    "Projects can belong to very different categories. The most popular ones - in terms of numbre of projects are \"Music\" and \" Film & Video\", followed by \"Publishing\", \"Art\" and \"Technology\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clear-breast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of project counts in relation to category\n",
    "ax = sns.countplot(y = df.parent_category_name, color = COLOR_CATEGORY)\n",
    "\n",
    "ax.set(ylabel=\"\")\n",
    "ax.set(xlabel=\"Number of projects\")\n",
    "\n",
    "xlabels = ['{:,.0f}'.format(x) for x in ax.get_xticks()]\n",
    "ax.set_xticklabels(xlabels)\n",
    "\n",
    "#plt.savefig(\"images/category_count.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focal-behalf",
   "metadata": {},
   "source": [
    "Are certain categories more successful than others? For the sake of simplicity of the next plot we also created a success rate column in relation for each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becoming-tournament",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_category = df.groupby(df['parent_category_name']).success.mean().reset_index().rename(columns={\"success\":\"success_category\"})\n",
    "df = df.merge(s_category, how = 'outer', left_on = 'parent_category_name', right_on = 'parent_category_name')\n",
    "s_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grave-bridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of success rate in relation to category\n",
    "ax = sns.barplot(y = df.parent_category_name, x = df.success_category, color = COLOR_SUCCESS)\n",
    "\n",
    "ax.set(ylabel=\"\")\n",
    "ax.set(xlabel=\"Success in percent\")\n",
    "\n",
    "xlabels = ['{:,.0f}'.format(x) for x in ax.get_xticks()*100]\n",
    "ax.set_xticklabels(xlabels)\n",
    "\n",
    "#plt.savefig(\"images/category_success.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specified-algorithm",
   "metadata": {},
   "source": [
    "THis plot looks very different to the above count of projects per category. The most successful projects are running the categories \"Comics\" and \"Dance\" (above 70%). In both categories the number of projects is fairly low compared to other categories and the funding goals are very low. The least successful categories are Food, Journalism and Technology (below 35%).\n",
    "\n",
    "When looking a the number of backers we see something slightly different. The most backers are supporting projects in the category \"Games\" - by far! Next is Desgin, closely followed by Technology and Comics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behavioral-ratio",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(df['parent_category_name']).usd_goal.mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "similar-water",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.barplot(y = df.parent_category_name, x= df.backers_count, color = COLOR_CATEGORY, ci =None)\n",
    "\n",
    "ax.set(ylabel=\"\")\n",
    "ax.set(xlabel=\"Number of backers\")\n",
    "\n",
    "#plt.savefig(\"images/category_backers.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conceptual-pittsburgh",
   "metadata": {},
   "source": [
    "When looking at the averaged pledged amount per category, we can see that Technology projects are very popular. However, it does not result in a successful outcome - as seen above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authorized-horror",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.barplot(y = df.parent_category_name, x= df.pledged_average, color = COLOR_CATEGORY, ci= None)\n",
    "\n",
    "ax.set(ylabel=\"\")\n",
    "ax.set(xlabel=\"Average pledged amount in USD\")\n",
    "\n",
    "#plt.savefig(\"images/category_pledged_av.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electric-prayer",
   "metadata": {},
   "source": [
    "## 4.5 Staff pick"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tribal-juvenile",
   "metadata": {},
   "source": [
    "When a project is picked by kcikstarter staff is put in a certain spotlight and highlighted on the website. We would think this should have an effect on the success rate. Let's see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "external-improvement",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_pick = df.groupby(df['staff_pick']).success.mean().reset_index().rename(columns={\"success\":\"success_pick\"})\n",
    "df = df.merge(s_pick, how = 'outer', left_on = 'staff_pick', right_on = 'staff_pick')\n",
    "s_pick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "random-villa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(df['staff_pick']).success.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offensive-adventure",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(df['staff_pick']).success.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatal-professional",
   "metadata": {},
   "source": [
    "Indeed! Just about 11% of all projects were staff picks. However these were than very successful - with a rate of about 87%. Projects that weren't picked showed a success rate of about 48%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpful-showcase",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "labels = [' ', \n",
    "         'Staff pick']\n",
    "percentages = [89.3, 10.7]\n",
    "explode=(0.1,0)\n",
    "ax.pie(percentages, explode=explode, labels=labels, autopct='%1.0f%%', \n",
    "       shadow=False, startangle=0,  colors = ['#9ecae1', '#08306b'] ,\n",
    "       pctdistance=1.2,labeldistance=1.4)\n",
    "ax.axis('equal')\n",
    "\n",
    "#plt.savefig(\"images/staffpick.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becoming-plane",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "labels = ['Successful', \n",
    "         '']\n",
    "percentages = [86.7, 13.3]\n",
    "explode=(0.1,0)\n",
    "plt.title('Staff pick')\n",
    "ax.pie(percentages, explode=explode, labels=labels, autopct='%1.0f%%', \n",
    "       colors = ['#7a0177', '#8c96c6', ],\n",
    "       shadow=False, startangle=0,   \n",
    "       pctdistance=1.2,labeldistance=1.4)\n",
    "ax.axis('equal')\n",
    "\n",
    "#plt.savefig(\"images/staffpick_success.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smaller-rehabilitation",
   "metadata": {},
   "source": [
    "Particularly projects from the categories \"Film & Video\" and \"Publishing\" are picked by Kickstarter staff, whereas projects in \"Crafts\" and \"Journalism\" are less likely to be picked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becoming-petroleum",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(df['staff_pick']).parent_category_name.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liberal-atlanta",
   "metadata": {},
   "source": [
    "## 4.6 Disable communication\n",
    "\n",
    "Something we haven't looked at so far is a feature that seems to be minor: disable communication. Let's calculated the success rate ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focal-africa",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_comm = df.groupby(df['disable_communication']).success.mean().reset_index().rename(columns={\"success\":\"success_comm\"})\n",
    "df = df.merge(s_comm, how = 'outer', left_on = 'disable_communication', right_on = 'disable_communication')\n",
    "\n",
    "s_comm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legitimate-module",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(df['disable_communication']).state.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "magnetic-craft",
   "metadata": {},
   "source": [
    "Above you can see that when communication is disabled there is no success at all. How come?\n",
    "\n",
    "When we look at the state of projects in relation to disabled communication we see that all projects where communication was disabled have been suspended by Kickstarter!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "utility-pepper",
   "metadata": {},
   "source": [
    "## 4.7 Projects that are \"starrable\"\n",
    "\n",
    "Another - maybe minor - feature is \"is_starrable\". What information does it hold, i.e. does it affect the success of a project?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arabic-arrangement",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_star = df.groupby(df['is_starrable']).success.mean().reset_index().rename(columns={\"success\":\"success_star\"})\n",
    "df = df.merge(s_star, how = 'outer', left_on = 'is_starrable', right_on = 'is_starrable')\n",
    "\n",
    "s_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "motivated-breakfast",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(df['is_starrable']).state.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scientific-couple",
   "metadata": {},
   "source": [
    "All projects that are starrable are still live and we cannot assume the success by this feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "knowing-poverty",
   "metadata": {},
   "source": [
    "# 5. Prepare data for model training \n",
    "## 5.1 Define target:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desirable-value",
   "metadata": {},
   "source": [
    "The aim of this project is to help potential project creators assess whether or not Kickstarter is a good funding option for them. Therefore, we want to model the chances to successfully raise enough money on Kickstarter. Kickstarter allwos backers to cancel their pledge and creators to cancel funding while the project is live. According to these cancellation policies, live or canceled projects could still miss the funding goal at the deadline although they had reached the funding goal earlier. Therefore, we only include successful, failed, and suspended projects in our analysis, treating failed and suspended both as not successful.\n",
    "\n",
    "Let's check the distribution of state classes before removing live and canceled data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "otherwise-routine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of projects per state\n",
    "df.groupby(\"state\").backers_count.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "determined-income",
   "metadata": {},
   "source": [
    "Most of the projects are recorded as failed or successful. What percentage of data would we drop by removing live and canceled projects?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imposed-winner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of live and canceled data\n",
    "df.query(\"state in ['live', 'canceled']\").shape[0]/df.shape[0] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boring-chapter",
   "metadata": {},
   "source": [
    "We drop ~7.3% of the data.\n",
    "\n",
    "We generate a new target column with 1 for successful projects and 0 for failed and suspended projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rocky-volunteer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target(row):\n",
    "    if row.state == \"successful\":\n",
    "        return 1\n",
    "    elif row.state in [\"failed\", \"suspended\"]:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supported-edinburgh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the new target column\n",
    "df[\"successful\"] = df.apply(lambda row: target(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-clone",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop live and canceled projects (they are the only rows with NaN values)\n",
    "df.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geological-contribution",
   "metadata": {},
   "source": [
    "## 5.2 Check for inbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cosmetic-bleeding",
   "metadata": {},
   "source": [
    "Let's check the class distribution of our target variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cubic-riverside",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.successful.value_counts() / df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vanilla-infection",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of projects with duplicate ID: {(df.id.value_counts() == 2).sum()}\") \n",
    "print(f\"Number of observations: {df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frank-pledge",
   "metadata": {},
   "source": [
    "With a class distribution of 60% successful and 39% unsuccessful we have an almost balanced dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nuclear-folder",
   "metadata": {},
   "source": [
    "# 6. Modeling\n",
    "\n",
    "Although we found differences in success depending on the year of the launch, including it in the modeling could lead to overfitting to old economic situations. Information such as \"your project would have been successful in 2013\" is not relevant for our stakeholder who wants to realize their project now.\n",
    "\n",
    "We include features in our model, that are known/decided on project creation such as the funding goal in US Dollar, the country of the project, the duration of the funding, the duration of project preparation, the name of the parent category, and the name of the subcategory.\n",
    "\n",
    "As target we choose whether or not a project was successful, as perpared above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "labeled-graph",
   "metadata": {},
   "source": [
    "## 6.1 Define target (y) and features (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revised-literature",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features\n",
    "features = [\"usd_goal\", \"country\", \"duration\", \"prep_time\",  \"parent_category_name\", \"category_name\"]\n",
    "X = df[features]\n",
    "\n",
    "# Select target\n",
    "y = df.successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relative-damage",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single-ticket",
   "metadata": {},
   "source": [
    "## 6.2 Spliting the data in train and test sets\n",
    "To be able to choose a model based on its performance on unseen data, we split our dataset into training and test set. We choose a random seed to have a reproducible split and no data leakage in our model selection process.\n",
    "\n",
    "The split was realized with sklearns train_test_split method, with a 70/30 ratio, random_state = 42 and stratify = target (the latter shall secure that the propration of values in the training and test set have the same proportion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incoming-hobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data in test and training set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mobile-wallet",
   "metadata": {},
   "source": [
    "## 6.3 Function definations\n",
    "\n",
    "Helper functions for training and evaluation of the different classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guided-manufacturer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_eval_plot_model(X_train, X_test, y_train, y_test, clf, cv=None):\n",
    "    \"\"\"Train a single model and print evaluation metrics.\n",
    "    \n",
    "    Args:\n",
    "        X_train (pd.DataFrame, np.array): Features of the training set\n",
    "        X_test (pd.DataFrame, np.array): Features of thee test set\n",
    "        y_train (pd.Series, np.array): Target of the training set\n",
    "        y_teset (pd.Seeries, np.array): Target of the test set\n",
    "        clf (sklearn.base.BaseEstimator): Estimator to train and use\n",
    "        cv (int, None): Number of cross-validations, default=None\n",
    "    \n",
    "    Returns:\n",
    "        model (sklearn.base.BaseEstimator): The trained model\n",
    "    \"\"\"\n",
    "    model = clf.fit(X_train, y_train)\n",
    "\n",
    "    if cv:\n",
    "        cv = cross_validate(m_rf, X_train_trans, y_train, cv=5, verbose=5)\n",
    "        print(f\"Best cross-validated score: {cv['test_score'].mean()}\")\n",
    "    \n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    print(f\"--- MODEL PARAMETERS {'-'*10}\")\n",
    "    print(json.dumps(model.get_params(), indent=4))\n",
    "    print(f\"--- CLASSIFICATION REPORT {'-'*10}\")\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    print(f\"--- CONFUSION MATRIX {'-'*10}\")\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    plot_confusion_matrix(model, X_test, y_test, display_labels=[\"unsuccessful\", \"successful\"])\n",
    "    return model\n",
    "\n",
    "def _pred_eval_plot_grid(X_train, X_test, y_train, y_test, gs):\n",
    "    \"\"\"Helper function to perform a grid search and calculate performance metrics.\n",
    "    \n",
    "    Args:\n",
    "        X_train (pd.DataFrame, np.array): Features of the training set\n",
    "        X_test (pd.DataFrame, np.array): Features of thee test set\n",
    "        y_train (pd.Series, np.array): Target of the training set\n",
    "        y_teset (pd.Seeries, np.array): Target of the test set\n",
    "        gs (BaseSearchCV): SearchCV to train and use\n",
    "    \n",
    "    Returns:\n",
    "        model (BaseSearchCV): The trained grid search\n",
    "    \"\"\"\n",
    "    gs = gs.fit(X_train, y_train)\n",
    "    \n",
    "    # Testing predictions (to determine performance)\n",
    "    y_pred = gs.best_estimator_.predict(X_test)\n",
    "    \n",
    "    print(f\"--- GRID SEARCH RESULTS {'-'*10}\")\n",
    "    print(f\"Best model: {gs.best_params_}\")\n",
    "    print(f\"Best cross-validated score: {gs.best_score_}\")\n",
    "    print(f\"--- CLASSIFICATION REPORT {'-'*10}\")\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    print(f\"--- CONFUSION MATRIX {'-'*10}\")\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    plot_confusion_matrix(gs.best_estimator_, X_test, y_test y_test, display_labels=[\"unsuccessful\", \"successful\"])\n",
    "    return gs\n",
    "    \n",
    "\n",
    "def run_rand_grid_search(X_train, X_test, y_train, y_test, clf, params_grid, n_iter=10, cv=5):\n",
    "    \"\"\"Perform a randomized grid search and calculate performance metrics.\n",
    "    \n",
    "    Args:\n",
    "        X_train (pd.DataFrame, np.array): Features of the training set\n",
    "        X_test (pd.DataFrame, np.array): Features of thee test set\n",
    "        y_train (pd.Series, np.array): Target of the training set\n",
    "        y_teset (pd.Seeries, np.array): Target of the test set\n",
    "        clf (sklearn.base.BaseEstimator): Estimator to train and use\n",
    "        params_grid (dict): Dictionary defining the parameters for the grid search\n",
    "        n_iter (int): Number of grid search combinations to run\n",
    "        cv (int, None): Number of cross-validations, default=None\n",
    "        \n",
    "    Returns:\n",
    "        model (BaseSearchCV): The trained grid search\n",
    "    \"\"\"\n",
    "    gs = RandomizedSearchCV(clf, params_grid, n_iter=n_iter, cv=cv, random_state=24, verbose=5)\n",
    "    return _pred_eval_plot_grid(X_train, X_test, y_train, y_test, gs)\n",
    "    \n",
    "def run_grid_search(X_train, X_test, y_train, y_test, clf, params_grid, cv=5):\n",
    "    \"\"\"Perform a grid search and calculate performance metrics.\n",
    "    \n",
    "    Args:\n",
    "        X_train (pd.DataFrame, np.array): Features of the training set\n",
    "        X_test (pd.DataFrame, np.array): Features of thee test set\n",
    "        y_train (pd.Series, np.array): Target of the training set\n",
    "        y_teset (pd.Seeries, np.array): Target of the test set\n",
    "        clf (sklearn.base.BaseEstimator): Estimator to train and use\n",
    "        params_grid (dict): Dictionary defining the parameters for the grid search\n",
    "        cv (int, None): Number of cross-validations, default=None\n",
    "        \n",
    "    Returns:\n",
    "        model (BaseSearchCV): The trained grid search\n",
    "    \"\"\"\n",
    "    gs = GridSearchCV(clf, params_grid, cv=cv, verbose=5)\n",
    "    return _pred_eval_plot_grid(X_train, X_test, y_train, y_test, gs)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lovely-network",
   "metadata": {},
   "source": [
    "## 6.4 Preparation of Data Scaling and Category Encoding\n",
    "\n",
    "Some models need scaling of numerical features and encoding of categorical features. The sklearn preprocessors are instantiated here and used where necessary in the data transformation step of each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unique-table",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder for categories\n",
    "onehot = OneHotEncoder(drop=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "international-sender",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scalers for numerical features\n",
    "mms = MinMaxScaler()\n",
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "western-hierarchy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare list of numerical and categorical columns\n",
    "num_cols = make_column_selector(dtype_include=np.number)\n",
    "cat_cols = make_column_selector(dtype_include=\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stable-reasoning",
   "metadata": {},
   "source": [
    "## 6.5. Choosing a metric\n",
    "\n",
    "We need to define a suitable metric for evaluating model performance. We saw earlier, that we have nearly equally distributed classes. Therfore, we use accuracy for model selection during grid search.\n",
    "\n",
    "For our final model selection and parameter tuning, we want to be sure that we predict success only in case the project was really successful. Hence, we use precision as final model metric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "above-integer",
   "metadata": {},
   "source": [
    "# 7. Modeltesting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affected-floor",
   "metadata": {},
   "source": [
    "## 7.1 Logistic Regression\n",
    "### Data Transformation\n",
    "For Logistic Regression we need to scale our data and encode categorical data. As the categories are not ordinal, we use one-hot-encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adolescent-theory",
   "metadata": {},
   "source": [
    "### 7.1.1 Simple Logistic Regression with Standard Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abandoned-revelation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformer\n",
    "transformer = ColumnTransformer([\n",
    "    (\"scale\", ss, num_cols),\n",
    "    (\"encode\", onehot, cat_cols),\n",
    "])\n",
    "\n",
    "# Transform\n",
    "X_train_trans = transformer.fit_transform(X_train)\n",
    "X_test_trans = transformer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "black-briefing",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_ss = LogisticRegression(max_iter=400)\n",
    "m_logreg_ss = pred_eval_plot_model(X_train_trans, X_test_trans, y_train, y_test, logreg_ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "familiar-acceptance",
   "metadata": {},
   "source": [
    "The basic model with standard scaling of the numerical features achieves an accuracy of 74% and a precision of 78% on successful projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trained-yukon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "y_probs = m_logreg_ss.predict_proba(X_test_trans)[:, 1]\n",
    "\n",
    "y_pred = y_probs > 0.9\n",
    "print(f\"--- CLASSIFICATION REPORT {'-'*10}\")\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(f\"--- CONFUSION MATRIX {'-'*10}\")\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "steady-egypt",
   "metadata": {},
   "source": [
    "Adjusting the threshold to 0.9, the precision for successful projects can be increased to 99%, reducing the accuracy to 61%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instant-lesbian",
   "metadata": {},
   "source": [
    "### 7.1.2 Simple Logistic Regression with MinMax Scaling\n",
    "\n",
    "For comparison we will try MinMax scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "traditional-finland",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformer\n",
    "transformer = ColumnTransformer([\n",
    "    (\"scale\", mms, num_cols),\n",
    "    (\"encode\", onehot, cat_cols),\n",
    "])\n",
    "\n",
    "# Transform\n",
    "X_train_trans = transformer.fit_transform(X_train)\n",
    "X_test_trans = transformer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gross-teaching",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the LogisticRegression\n",
    "logreg = LogisticRegression(max_iter=400)\n",
    "m_logreg_mm = pred_eval_plot_model(X_train_trans, X_test_trans, y_train, y_test, logreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "labeled-massachusetts",
   "metadata": {},
   "source": [
    "Using MinMax scaling, the model has an accuracy of 74% and precision of 78%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "declared-filename",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "y_probs = m_logreg_mm.predict_proba(X_test_trans)[:, 1]\n",
    "\n",
    "y_pred = y_probs > 0.9\n",
    "print(f\"--- CLASSIFICATION REPORT {'-'*10}\")\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(f\"--- CONFUSION MATRIX {'-'*10}\")\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applicable-address",
   "metadata": {},
   "source": [
    "The same results can be achieved by adjusting the threshold value: Decrease in accuracy to 61% for an increase in precision to 99%.\n",
    "\n",
    "Hence, we can not say, that one scaling outperforms the other in case of logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pregnant-solution",
   "metadata": {},
   "source": [
    "### 7.1.3 With Randomized Grid Search\n",
    "Let's try different regularization weights and types to improve the performance of the logistic regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vietnamese-harris",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_grid = {\n",
    "    \"penalty\": [\"elasticnet\"],\n",
    "    \"C\": np.logspace(-3, 3, 7),\n",
    "    \"max_iter\": [200],\n",
    "    \"l1_ratio\": np.arange(0, 1, 0.25),\n",
    "    \"solver\": [\"saga\"],\n",
    "}\n",
    "rs_logreg = run_rand_grid_search(X_train_trans, X_test_trans, y_train, y_test, logreg, params_grid, cv=3, n_iter=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thermal-faith",
   "metadata": {},
   "source": [
    "The best model with randomized search is achieved with {'solver': 'saga', 'penalty': 'elasticnet', 'max_iter': 200, 'l1_ratio': 0.75, 'C': 1000.0} With a cross-validated score of 0.7332417031755577.\n",
    "\n",
    "The accuracy of the best model is 74% and precision is 78%. Therefore, we could not find a parameter combination that improves precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crazy-honor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "y_probs = rs_logreg.best_estimator_.predict_proba(X_test_trans)[:, 1]\n",
    "\n",
    "y_pred = y_probs > 0.9\n",
    "print(f\"--- CLASSIFICATION REPORT {'-'*10}\")\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(f\"--- CONFUSION MATRIX {'-'*10}\")\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eligible-credits",
   "metadata": {},
   "source": [
    "Unsurprisingly, changing the threshold value gives the same results as before."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "touched-parts",
   "metadata": {},
   "source": [
    "## 7.2 KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civilian-gross",
   "metadata": {},
   "source": [
    "### Data Transformation\n",
    "KNN compares observations based on a similarity measure. Therefore, we need to scale numerical features and use one-hot-encoding for our categorical features. Using one-hot encoding creates a sparse matrix and reduces KNN efficiency. Therefore, we remove category_name from our features to reduce the number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaded-bradford",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_trans = X_train.copy()\n",
    "X_train_trans.pop(\"category_name\")\n",
    "X_test_trans = X_test.copy()\n",
    "X_test_trans.pop(\"category_name\")\n",
    "\n",
    "# Define transformer\n",
    "transformer = ColumnTransformer([\n",
    "    (\"scale\", ss, num_cols),\n",
    "    (\"encode\", onehot, make_column_selector(dtype_include=\"category\")),\n",
    "])\n",
    "\n",
    "# Transform\n",
    "X_train_trans = transformer.fit_transform(X_train)\n",
    "X_test_trans = transformer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generic-works",
   "metadata": {},
   "source": [
    "### 7.2.1 Simple KNN\n",
    "We will use the manhattan distance for similarity as our data is sparse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "million-reading",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Classifier\n",
    "knn = KNeighborsClassifier(p=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "treated-moses",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_eval_plot_model(X_train_trans , X_test_trans, y_train, y_test, knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silver-warrant",
   "metadata": {},
   "source": [
    "The model achieves a precision of 76% for successful projects. Training the KNN took very long and did not achieve large differences in precision. Therefore, we will not optimize KNN parameters with a grid saerch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nutritional-guarantee",
   "metadata": {},
   "source": [
    "## 7.3 Decision Tree\n",
    "\n",
    "### Data Transformation\n",
    "\n",
    "For Decision Trees numerical data doesn't need to be scaled. Categorical data needs to be encoded. As One-Hot-Encoding leads to sparse data and decreases the performance of decision trees, we encode the categories numerically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesser-phase",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical features (with more than two classes)\n",
    "X_train_trans = X_train.copy()\n",
    "X_test_trans = X_test.copy()\n",
    "for cat in [\"country\", \"parent_category_name\", \"category_name\"]:\n",
    "    X_train_trans[[cat]] = X_train_trans[cat].cat.codes\n",
    "    X_test_trans[[cat]] = X_test_trans[cat].cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifteen-parade",
   "metadata": {},
   "source": [
    "### 7.3.1 Simple Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rental-expansion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Classifier\n",
    "dtree = DecisionTreeClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laughing-shock",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_dtree = pred_eval_plot_model(X_train_trans, X_test_trans, y_train, y_test, dtree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "everyday-excuse",
   "metadata": {},
   "source": [
    "The accuracy of 70% and precision of 75% for being successful needs to be improved further. Let's do a grid search:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "announced-vatican",
   "metadata": {},
   "source": [
    "### 7.3.2 Decion Tree with grid search\n",
    "In the grid search we want to limit the depth of the tree and the minimum number of samples required to split a leaf. If we can improve the performance of the model on the test set by this regularization, the tree that was trained above with default values overfitted the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorrect-wisconsin",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_grid = {\n",
    "    \"max_depth\": np.arange(10, 50, 2),\n",
    "    \"min_samples_leaf\": np.arange(10, 30, 2),\n",
    "}\n",
    "rs_dtree = run_rand_grid_search(X_train_trans, X_test_trans, y_train, y_test, dtree, params_grid, n_iter=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loaded-prayer",
   "metadata": {},
   "source": [
    "With regularization parameters of {'min_samples_leaf': 26, 'max_depth': 18} the model accuracy can be improved by 4% to 74% and precision by 2% to 77%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "square-image",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the decision tree to a tree.dot file \n",
    "# for visualizing the plot easily anywhere \n",
    "export_graphviz(rs_dtree.best_estimator_, out_file ='tree.dot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "another-ability",
   "metadata": {},
   "source": [
    "## 7.4 Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cross-blast",
   "metadata": {},
   "source": [
    "### Data Transformation\n",
    "For Random Forests we use the same data scaling and encoding as for decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banner-louisiana",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical features (with more than two classes)\n",
    "X_train_trans = X_train.copy()\n",
    "X_test_trans = X_test.copy()\n",
    "for cat in [\"country\", \"parent_category_name\", \"category_name\"]:\n",
    "    X_train_trans[[cat]] = X_train_trans[cat].cat.codes\n",
    "    X_test_trans[[cat]] = X_test_trans[cat].cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "realistic-winning",
   "metadata": {},
   "source": [
    "### 7.4.1 Simple Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dress-batman",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Classifier\n",
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strategic-croatia",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_rf = pred_eval_plot_model(X_train_trans, X_test_trans, y_train, y_test, rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooked-adaptation",
   "metadata": {},
   "source": [
    "Random Forest Classifier with default parameters has an accuracy of 75% and precision of 77%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outstanding-maine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate some stats for the random forest:\n",
    "n_nodes = []\n",
    "max_depths = []\n",
    "\n",
    "# Stats about the trees in random forest\n",
    "for ind_tree in m_rf.estimators_:\n",
    "    n_nodes.append(ind_tree.tree_.node_count)\n",
    "    max_depths.append(ind_tree.tree_.max_depth)\n",
    "    \n",
    "print(f'Average number of nodes {int(np.mean(n_nodes))}')\n",
    "print(f'Average maximum depth {int(np.mean(max_depths))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nuclear-machine",
   "metadata": {},
   "source": [
    "### 7.4.2 Grid Search on random forest\n",
    "We want to check whether we can improve the performance of the random forest by changing the split-criterion. We will not regularize the depth of the tree and the minimum samples per leaf, as we are averaging the classification of 100 trees. Therefore, we assume that no additional regularization is necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resistant-stylus",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_grid = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "}\n",
    "rs_rf = run_grid_search(X_train_trans, X_test_trans, y_train, y_test, rf,  params_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impossible-fraud",
   "metadata": {},
   "source": [
    "According to the Grid Search, entropy is the better criterion to select features and split-values, but accuracy and precision could not be improved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "orange-sustainability",
   "metadata": {},
   "source": [
    "## 7.5 ExtraTree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atomic-devon",
   "metadata": {},
   "source": [
    "### Data Transformation\n",
    "Still working with trees, we keep the same data transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naval-gather",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_trans = X_train.copy()\n",
    "X_test_trans = X_test.copy()\n",
    "for cat in [\"country\", \"parent_category_name\", \"category_name\"]:\n",
    "    X_train_trans[[cat]] = X_train_trans[cat].cat.codes\n",
    "    X_test_trans[[cat]] = X_test_trans[cat].cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organizational-guide",
   "metadata": {},
   "source": [
    "### 7.5.1 Simple ExtraTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verified-period",
   "metadata": {},
   "outputs": [],
   "source": [
    "etree = ExtraTreesClassifier()\n",
    "m_etree = pred_eval_plot_model(X_train_trans, X_test_trans, y_train, y_test, etree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessible-yukon",
   "metadata": {},
   "source": [
    "ExtraTreeClassifier has an accuracy of 74% and precision of 77% out of the box."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corporate-savannah",
   "metadata": {},
   "source": [
    "## 7.6 XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secure-romantic",
   "metadata": {},
   "source": [
    "### Data Transformation\n",
    "As XGBoost is working with trees, we use the same data transformation where we encode categories numerically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inappropriate-dancing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformer\n",
    "transformer = ColumnTransformer([\n",
    "    (\"scale\", ss, num_cols),\n",
    "    (\"encode\", onehot, cat_cols),\n",
    "])\n",
    "\n",
    "# Transform\n",
    "X_train_trans = transformer.fit_transform(X_train)\n",
    "X_test_trans = transformer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focused-mentor",
   "metadata": {},
   "source": [
    "### 7.6.1 Simple XGB Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "commercial-individual",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Classifier\n",
    "xgb = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scheduled-pension",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_eval_plot_model(X_train_trans, X_test_trans, y_train, y_test, xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demographic-border",
   "metadata": {},
   "source": [
    "XGBoost has an accuracy of 77% and precision of 80%, showing the best prediction results so far."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coupled-baking",
   "metadata": {},
   "source": [
    "# 8. Modeling conclusion\n",
    "\n",
    "Model | Accuracy [\\%] | Precision [\\%]\n",
    "--- | --- | ---\n",
    "Logistic Regression | 74 | 78\n",
    "Logistic Regression Threshold 0.9 | 61 | 99\n",
    "KNN | 72 | 76\n",
    "Decision Tree | 74 | 77\n",
    "Random Forest | 75 | 77\n",
    "Extra Tree | 74 | 78\n",
    "XGBoost | 77 | 80\n",
    "\n",
    "As the performance metrics were similar, we choose Logistic Regression as it was fast to train and allows for adjusting the treshold. Thereby, we can improve precision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "juvenile-vermont",
   "metadata": {},
   "source": [
    "# 9. Future work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grand-hypothesis",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "* Remove duplicates (based on id): There are still duplicates in our dataset. Further investigation why projects are listed twice and removing unnecessary observations improves the quality of the data set.\n",
    "* Extract more detailed location information: More detailed information on location (e.g. the city) is given in the `location` column.\n",
    "\n",
    "### Feature Engineering\n",
    "+ Check and clean subcategory names\n",
    "\n",
    "### Modeling\n",
    "* Include a simple base model (predicting all projects as successful)\n",
    "* Try more sophisticated models: e.g. stacked model, optimize XGBoost parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experienced-polymer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "domestic-price",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threaded-respondent",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
